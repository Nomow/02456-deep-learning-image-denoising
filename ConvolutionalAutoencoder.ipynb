{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPqWGqQeejhY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqojrNaSss2A"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import data\n",
    "  import dataset\n",
    "  import utils\n",
    "except:\n",
    "  print(\"Remember to load the python files to colab\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4jjXrVOsbY0",
    "outputId": "b41e19a9-f20a-4e34-cfb3-af597f2be8e3"
   },
   "outputs": [],
   "source": [
    "!cd ..\n",
    "!mkdir data\n",
    "!cd data\n",
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz\n",
    "!rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Or006izmu-f4",
    "outputId": "04151ded-25d5-4f03-bff4-e30d67420813"
   },
   "outputs": [],
   "source": [
    "!pip install -U albumentations\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2jx5OpMgC4g",
    "outputId": "d8ec6675-e0ae-4385-f503-3aa13b3f8762"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeabDelStMzU"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.load_cifar_10_data(\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDTfph3_slw4"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# transform = {\n",
    "#         'train': transforms.Compose([\n",
    "#             transforms.Resize((32, 32)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, ), (0.5, ))\n",
    "#         ]),\n",
    "#         'test': transforms.Compose([\n",
    "#             transforms.Resize((32, 32)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, ), (0.5, ))\n",
    "#         ])\n",
    "#     }\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.GaussNoise(var_limit=(30, 70), mean=0, p=1),\n",
    "    # A.MultiplicativeNoise()\n",
    "    # A.Blur(p=1)\n",
    "    A.CoarseDropout(max_height=2, max_width=2, min_holes=2, max_holes=5)\n",
    "])\n",
    "\n",
    "preprocess_transform = A.Compose([\n",
    "    # transforms.Resize((32, 32)),\n",
    "    A.Normalize(mean = [0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ToTensorV2()\n",
    "    \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "trainset = dataset.Cifar10AutoEncoderDataset(train_data, preprocess_transform, transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = dataset.Cifar10AutoEncoderDataset(test_data, preprocess_transform, transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wx2F7sMBCzA"
   },
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "  image = np.swapaxes(np.swapaxes(img.numpy(), 0, 2), 0, 1)\n",
    "  MEAN = 255 * np.array([0.5, 0.5, 0.5])\n",
    "  STD = 255 * np.array([0.5, 0.5, 0.5])\n",
    "  image = ((image * STD)+ MEAN).astype(int)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "XrlMzTwpxIGI",
    "outputId": "acb01c48-2e2d-4bd1-f530-f98172f5282d"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure()\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(denormalize(images[i]))\n",
    "    # plt.imshow(images[i].numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(denormalize(labels[i]))\n",
    "    # plt.imshow(labels[i].numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVNug1Ry9KxU"
   },
   "source": [
    "Old version, has a very big latent space - more like a U-net than autoencoder.\n",
    "Here, the bottleneck encodes $4*4*128=2048$ features, which is close to $32*32*3=3072$ pixel values of hte input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6aqKM0ggWRI"
   },
   "outputs": [],
   "source": [
    "### Old version, has a very big latent space - more like a unet than autoencoder\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv(self.pool2(e2)))\n",
    "      \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNwm5zlr9OCs"
   },
   "source": [
    "This version is actually more like an autoencoder, has a bottleneck that encodes $4*4*16 = 256$ features, which is a compression from $32*32*3 = 3072$ pixels of the input image (not a giant one, but okay given the variety of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HddfXY9R6VIU"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder2, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv1 = nn.Conv2d(128, 16, 3, padding=1)\n",
    "        self.bottleneck_conv2 = nn.Conv2d(16, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-khkusiCVKo"
   },
   "source": [
    "[This](https://towardsdatascience.com/aligning-hand-written-digits-with-convolutional-autoencoders-99128b83af8b) article suggests that it is better to use upsampling/maxpooling instead of deconvolutions and convolutions with stride. Additionally, it shows that it is best to use fully connected layers for the bottleneck. I will test that here.\n",
    "\n",
    "**Results**\n",
    "\n",
    "The upsamling/maxpooling results in much worse training. The fully connected bottleneck seems to have simillar results as the convolutional. In the end, I will test the skip connections on both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXAvtsVDCVgg"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder3, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.flatten = torch.nn.Flatten() # 4*4*128 = 2048\n",
    "        self.bottleneck1 = nn.Linear(2048, 256)\n",
    "        self.bottleneck2 =  nn.Linear(256, 2048)\n",
    "        # self.bottleneck_conv1 = nn.Conv2d(128, 16, 3, padding=1)\n",
    "        # self.bottleneck_conv2 = nn.Conv2d(16, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        flat = self.flatten(self.pool2(e2))\n",
    "        b = F.leaky_relu(self.bottleneck2(F.leaky_relu(self.bottleneck1(flat))))\n",
    "        reshaped = torch.reshape(b, (-1,128,4,4))\n",
    "        # b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(reshaped)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0BdYdlz_PwQ"
   },
   "source": [
    "Autoencoder with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuOXviFU_P4E"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoderSkip(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoderSkip, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv1 = nn.Conv2d(128, 16, 3, padding=1)\n",
    "        self.bottleneck_conv2 = nn.Conv2d(16, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(256, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(torch.cat([self.upsample0(b), e2], 1)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(torch.cat([self.upsample1(d0),e1], 1)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(torch.cat([self.upsample2(d1),e0], 1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vtx90LWrS8yg"
   },
   "source": [
    "Version with fully connected bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcrBcV2KS71k"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoderSkip2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoderSkip2, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.flatten = torch.nn.Flatten() # 4*4*128 = 2048\n",
    "        self.bottleneck1 = nn.Linear(2048, 256)\n",
    "        self.bottleneck2 =  nn.Linear(256, 2048)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(256, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        flat = self.flatten(self.pool2(e2))\n",
    "        b = F.leaky_relu(self.bottleneck2(F.leaky_relu(self.bottleneck1(flat))))\n",
    "        reshaped = torch.reshape(b, (-1,128,4,4))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(torch.cat([self.upsample0(reshaped), e2], 1)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ncDLpoG42rQ"
   },
   "outputs": [],
   "source": [
    "def train(model, opt, epochs):\n",
    "\n",
    "    def loss_fun(y_real, y_pred):\n",
    "      # loss = nn.CrossEntropyLoss(weight=torch.tensor([1,5]).float().to(device))\n",
    "      loss = torch.nn.MSELoss()\n",
    "      # output = loss(y_pred, y_real.squeeze(1).long())\n",
    "      output = loss(y_pred, y_real)\n",
    "      return output\n",
    "\n",
    "    X_val, Y_val = next(iter(test_loader))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for minibatch_no, (X_batch, Y_batch) in enumerate(train_loader, 0):\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            loss = loss_fun(Y_batch, Y_pred)  # forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            # calculate metrics to show the user\n",
    "            avg_loss += loss / len(X_batch)\n",
    "        toc = time()\n",
    "        print(' - loss: %f' % avg_loss)\n",
    "\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        Y_hat = model(X_val.to(device)).detach().cpu()\n",
    "        predicted = Y_hat\n",
    "        clear_output(wait=True)\n",
    "        k = 0\n",
    "        for m in range(6):\n",
    "          plt.subplot(3, 6, k+1)\n",
    "          plt.imshow(denormalize(X_val[m]))\n",
    "          # plt.imshow(X_val[m][0].numpy(), cmap='gray')\n",
    "          plt.title('Input')\n",
    "          plt.axis('off')\n",
    "\n",
    "          plt.subplot(3, 6, k+7)\n",
    "          plt.imshow(denormalize(predicted[m]))\n",
    "          # plt.imshow(predicted[m], cmap='gray')\n",
    "          plt.title('Output')\n",
    "          plt.axis('off')\n",
    "\n",
    "          plt.subplot(3, 6, k+13)\n",
    "          plt.imshow(denormalize(Y_val[m]))\n",
    "          # plt.imshow(Y_val[m][0], cmap='gray')\n",
    "          plt.title('Target')\n",
    "          plt.axis('off')\n",
    "          \n",
    "          k+=1\n",
    "        plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "QVCnM68T5C28",
    "outputId": "dd72ea7b-2be5-4426-a4c7-b60980c47069"
   },
   "outputs": [],
   "source": [
    "model = ConvAutoEncoder().to(device)\n",
    "train(model, optim.Adam(model.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "mKxgKWrj8jV4",
    "outputId": "77ae3bd0-fd4a-4731-a6fa-2c343d380be3"
   },
   "outputs": [],
   "source": [
    "model2 = ConvAutoEncoder2().to(device)\n",
    "train(model2, optim.Adam(model2.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "RxX07nyTE0hE",
    "outputId": "0b70556d-f276-470b-89bc-76124b1d9fb2"
   },
   "outputs": [],
   "source": [
    "model3 = ConvAutoEncoder3().to(device)\n",
    "train(model3, optim.Adam(model3.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Glq_UyQiI3vs",
    "outputId": "29dc3de9-78e8-4658-ee97-a7c46932100c"
   },
   "outputs": [],
   "source": [
    "# After removing fully connected layer\n",
    "model3 = ConvAutoEncoder3().to(device)\n",
    "train(model3, optim.Adam(model3.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "696TR6joOB_o",
    "outputId": "3e44b4cc-1a61-44c5-b449-d6f045a93fe2"
   },
   "outputs": [],
   "source": [
    "# After removing alternative downsampling/upsampling\n",
    "model3 = ConvAutoEncoder3().to(device)\n",
    "train(model3, optim.Adam(model3.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "1k1Kz1PXArEA",
    "outputId": "db5e2fbe-781f-44ca-b023-edd48dc01e1a"
   },
   "outputs": [],
   "source": [
    "modelSkip = ConvAutoEncoderSkip().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "ZOYky51IVyHM",
    "outputId": "27f16887-0fe5-47b4-c27d-ce42fc7993a9"
   },
   "outputs": [],
   "source": [
    "modelSkip2 = ConvAutoEncoderSkip2().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip2.parameters()), 30)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ConvolutionalAutoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
