{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPqWGqQeejhY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqojrNaSss2A"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import data\n",
    "  import dataset\n",
    "  import utils\n",
    "except:\n",
    "  print(\"Remember to load the python files to colab\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4jjXrVOsbY0",
    "outputId": "b0034fb1-79b2-4717-8e77-59deb9a7266b"
   },
   "outputs": [],
   "source": [
    "!cd ..\n",
    "!mkdir data\n",
    "!cd data\n",
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz\n",
    "!rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "Or006izmu-f4",
    "outputId": "97742450-abdb-4cb7-dad8-07f1e74f31e5"
   },
   "outputs": [],
   "source": [
    "!pip install -U albumentations\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2jx5OpMgC4g",
    "outputId": "7e6e648b-0e44-4b10-ff7a-6d4892c8f4e4"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeabDelStMzU"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.load_cifar_10_data(\"cifar-10-batches-py\")\n",
    "\n",
    "idx_train = np.random.permutation(np.arange(0,len(train_data)))[:5000]\n",
    "idx_test = np.random.permutation(np.arange(0,len(test_data)))[:2000]\n",
    "train_data = train_data[idx_train]\n",
    "test_data = test_data[idx_test]\n",
    "\n",
    "\n",
    "# train_data = train_data[:5000]\n",
    "# test_data = test_data[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDTfph3_slw4"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# transform = {\n",
    "#         'train': transforms.Compose([\n",
    "#             transforms.Resize((32, 32)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, ), (0.5, ))\n",
    "#         ]),\n",
    "#         'test': transforms.Compose([\n",
    "#             transforms.Resize((32, 32)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, ), (0.5, ))\n",
    "#         ])\n",
    "#     }\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.GaussNoise(var_limit=(30, 100), mean=0, p=0.7),\n",
    "    # A.MultiplicativeNoise()\n",
    "    # A.Blur(p=1)\n",
    "    # A.CoarseDropout(max_height=2, max_width=2, min_holes=2, max_holes=5),\n",
    "    A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0, hue=0, always_apply=True, p=0.7)\n",
    "])\n",
    "\n",
    "preprocess_transform = A.Compose([\n",
    "    # transforms.Resize((32, 32)),\n",
    "    A.Normalize(mean = [0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ToTensorV2()\n",
    "    \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "trainset = dataset.Cifar10AutoEncoderDataset(train_data, preprocess_transform, transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = dataset.Cifar10AutoEncoderDataset(test_data, preprocess_transform, transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wx2F7sMBCzA"
   },
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "  image = np.swapaxes(np.swapaxes(img.numpy(), 0, 2), 0, 1)\n",
    "  MEAN = 255 * np.array([0.5, 0.5, 0.5])\n",
    "  STD = 255 * np.array([0.5, 0.5, 0.5])\n",
    "  image = ((image * STD)+ MEAN).astype(int)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "XrlMzTwpxIGI",
    "outputId": "57c31d84-63b8-4650-d386-af55e7885a1f"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure()\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(denormalize(images[i]))\n",
    "    # plt.imshow(images[i].numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(denormalize(labels[i]))\n",
    "    # plt.imshow(labels[i].numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVNug1Ry9KxU"
   },
   "source": [
    "Old version, has a very big latent space - more like a U-net than autoencoder.\n",
    "Here, the bottleneck encodes $4*4*128=2048$ features, which is close to $32*32*3=3072$ pixel values of hte input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6aqKM0ggWRI"
   },
   "outputs": [],
   "source": [
    "### Old version, has a very big latent space - more like a unet than autoencoder\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv(self.pool2(e2)))\n",
    "      \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNwm5zlr9OCs"
   },
   "source": [
    "This version is actually more like an autoencoder, has a bottleneck that encodes $4*4*16 = 256$ features, which is a compression from $32*32*3 = 3072$ pixels of the input image (not a giant one, but okay given the variety of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HddfXY9R6VIU"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder2, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv1 = nn.Conv2d(128, 16, 3, padding=1)\n",
    "        self.bottleneck_conv2 = nn.Conv2d(16, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-khkusiCVKo"
   },
   "source": [
    "[This](https://towardsdatascience.com/aligning-hand-written-digits-with-convolutional-autoencoders-99128b83af8b) article suggests that it is better to use upsampling/maxpooling instead of deconvolutions and convolutions with stride. Additionally, it shows that it is best to use fully connected layers for the bottleneck. I will test that here.\n",
    "\n",
    "**Results**\n",
    "\n",
    "The upsamling/maxpooling results in much worse training. The fully connected bottleneck seems to have simillar results as the convolutional. In the end, I will test the skip connections on both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXAvtsVDCVgg"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder3, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.flatten = torch.nn.Flatten() # 4*4*128 = 2048\n",
    "        self.bottleneck1 = nn.Linear(2048, 256)\n",
    "        self.bottleneck2 =  nn.Linear(256, 2048)\n",
    "        # self.bottleneck_conv1 = nn.Conv2d(128, 16, 3, padding=1)\n",
    "        # self.bottleneck_conv2 = nn.Conv2d(16, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        flat = self.flatten(self.pool2(e2))\n",
    "        b = F.leaky_relu(self.bottleneck2(F.leaky_relu(self.bottleneck1(flat))))\n",
    "        reshaped = torch.reshape(b, (-1,128,4,4))\n",
    "        # b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(reshaped)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0BdYdlz_PwQ"
   },
   "source": [
    "Autoencoder with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuOXviFU_P4E"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoderSkip(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoderSkip, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.enc_batchnorm_0 = nn.BatchNorm2d(32)\n",
    "        self.dropout0 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.enc_batchnorm_1 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.enc_batchnorm_2 = nn.BatchNorm2d(128)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv1 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bottleneck_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(256, 64, 3, padding=1)\n",
    "        self.dec_batchnorm_0 = nn.BatchNorm2d(64)\n",
    "        self.dec_dropout0 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_1 = nn.BatchNorm2d(32)\n",
    "        self.dec_dropout1 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_2 = nn.BatchNorm2d(32)\n",
    "        self.dec_dropout2 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = self.dropout0(F.leaky_relu(self.enc_batchnorm_0(self.enc_conv0(x))))\n",
    "        e1 = self.dropout1(F.leaky_relu(self.enc_batchnorm_1(self.enc_conv1(self.pool0(e0)))))\n",
    "        e2 = self.dropout2(F.leaky_relu(self.enc_batchnorm_2(self.enc_conv2(self.pool1(e1)))))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = self.dec_dropout0(F.leaky_relu(self.dec_batchnorm_0(self.dec_conv0(torch.cat([self.upsample0(b), e2], 1)))))\n",
    "        d1 = self.dec_dropout1(F.leaky_relu(self.dec_batchnorm_1(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1)))))\n",
    "        d2 = self.dec_dropout2(F.leaky_relu(self.dec_batchnorm_2(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1)))))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPempSSQ89bA"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoderSkipOld(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoderSkipOld, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.enc_batchnorm_0 = nn.BatchNorm2d(32)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.enc_batchnorm_1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.enc_batchnorm_2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv1 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bottleneck_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(256, 64, 3, padding=1)\n",
    "        self.dec_batchnorm_0 = nn.BatchNorm2d(64)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_1 = nn.BatchNorm2d(32)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_2 = nn.BatchNorm2d(32)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        # e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        # e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        # e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "        e0 = F.leaky_relu(self.enc_batchnorm_0(self.enc_conv0(x)))\n",
    "        e1 = F.leaky_relu(self.enc_batchnorm_1(self.enc_conv1(self.pool0(e0))))\n",
    "        e2 = F.leaky_relu(self.enc_batchnorm_2(self.enc_conv2(self.pool1(e1))))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv2(F.leaky_relu(self.bottleneck_conv1(self.pool2(e2)))))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_batchnorm_0(self.dec_conv0(torch.cat([self.upsample0(b), e2], 1))))\n",
    "        d1 = F.leaky_relu(self.dec_batchnorm_1(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1))))\n",
    "        d2 = F.leaky_relu(self.dec_batchnorm_2(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1))))\n",
    "        # d0 = F.leaky_relu(self.dec_conv0(torch.cat([self.upsample0(b), e2], 1)))\n",
    "        # d1 = F.leaky_relu(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1)))\n",
    "        # d2 = F.leaky_relu(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbrcoDnsgOY0"
   },
   "source": [
    "Version with fully connected bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HLtF7r8gSGU"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoderSkip2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoderSkip2, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.enc_batchnorm_0 = nn.BatchNorm2d(32)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.enc_batchnorm_1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.enc_batchnorm_2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.flatten = torch.nn.Flatten() # 4*4*128 = 2048\n",
    "        self.bottleneck1 = nn.Linear(2048, 1024)\n",
    "        self.bottleneck2 =  nn.Linear(1024, 2048)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(256, 64, 3, padding=1)\n",
    "        self.dec_batchnorm_0 = nn.BatchNorm2d(64)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_1 = nn.BatchNorm2d(32)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_2 = nn.BatchNorm2d(32)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_batchnorm_0(self.enc_conv0(x)))\n",
    "        e1 = F.leaky_relu(self.enc_batchnorm_1(self.enc_conv1(self.pool0(e0))))\n",
    "        e2 = F.leaky_relu(self.enc_batchnorm_2(self.enc_conv2(self.pool1(e1))))\n",
    "        # e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        # e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        # e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        flat = self.flatten(self.pool2(e2))\n",
    "        b = F.leaky_relu(self.bottleneck2(F.leaky_relu(self.bottleneck1(flat))))\n",
    "        reshaped = torch.reshape(b, (-1,128,4,4))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_batchnorm_0(self.dec_conv0(torch.cat([self.upsample0(reshaped), e2], 1))))\n",
    "        d1 = F.leaky_relu(self.dec_batchnorm_1(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1))))\n",
    "        d2 = F.leaky_relu(self.dec_batchnorm_2(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1))))\n",
    "        # d0 = F.leaky_relu(self.dec_conv0(torch.cat([self.upsample0(reshaped), e2], 1)))\n",
    "        # d1 = F.leaky_relu(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1)))\n",
    "        # d2 = F.leaky_relu(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8rLqU4ICUqM"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoderSkip2Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoderSkip2Dropout, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.enc_batchnorm_0 = nn.BatchNorm2d(32)\n",
    "        self.dropout0 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.enc_batchnorm_1 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.enc_batchnorm_2 = nn.BatchNorm2d(128)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.flatten = torch.nn.Flatten() # 4*4*128 = 2048\n",
    "        self.bottleneck1 = nn.Linear(2048, 1024)\n",
    "        self.bottleneck2 =  nn.Linear(1024, 2048)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(256, 64, 3, padding=1)\n",
    "        self.dec_batchnorm_0 = nn.BatchNorm2d(64)\n",
    "        self.dec_dropout0 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_1 = nn.BatchNorm2d(32)\n",
    "        self.dec_dropout1 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.dec_batchnorm_2 = nn.BatchNorm2d(32)\n",
    "        self.dec_dropout2 = nn.Dropout2d(p=0.1, inplace=False)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = self.dropout0(F.leaky_relu(self.enc_batchnorm_0(self.enc_conv0(x))))\n",
    "        e1 = self.dropout1(F.leaky_relu(self.enc_batchnorm_1(self.enc_conv1(self.pool0(e0)))))\n",
    "        e2 = self.dropout2(F.leaky_relu(self.enc_batchnorm_2(self.enc_conv2(self.pool1(e1)))))\n",
    "\n",
    "        # bottleneck\n",
    "        flat = self.flatten(self.pool2(e2))\n",
    "        b = F.leaky_relu(self.bottleneck2(F.leaky_relu(self.bottleneck1(flat))))\n",
    "        reshaped = torch.reshape(b, (-1,128,4,4))\n",
    "       \n",
    "        # decoder\n",
    "        d0 = self.dec_dropout0(F.leaky_relu(self.dec_batchnorm_0(self.dec_conv0(torch.cat([self.upsample0(reshaped), e2], 1)))))\n",
    "        d1 = self.dec_dropout1(F.leaky_relu(self.dec_batchnorm_1(self.dec_conv1(torch.cat([self.upsample1(d0), e1], 1)))))\n",
    "        d2 = self.dec_dropout2(F.leaky_relu(self.dec_batchnorm_2(self.dec_conv2(torch.cat([self.upsample2(d1), e0], 1)))))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ncDLpoG42rQ"
   },
   "outputs": [],
   "source": [
    "def train(model, opt, epochs):\n",
    "\n",
    "    def loss_fun(y_real, y_pred):\n",
    "      # loss = nn.CrossEntropyLoss(weight=torch.tensor([1,5]).float().to(device))\n",
    "      loss = torch.nn.MSELoss()\n",
    "      # output = loss(y_pred, y_real.squeeze(1).long())\n",
    "      output = loss(y_pred, y_real)\n",
    "      return output\n",
    "\n",
    "    X_val, Y_val = next(iter(test_loader))\n",
    "    valid_loss_list = []\n",
    "    train_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "        batch_loss_list = []\n",
    "        # avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for minibatch_no, (X_batch, Y_batch) in enumerate(train_loader, 0):\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            loss = loss_fun(Y_batch, Y_pred)  # forward-pass\n",
    "            batch_loss_list.append(loss.item())\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            # calculate metrics to show the user\n",
    "            # avg_loss += loss / len(X_batch)\n",
    "        toc = time()\n",
    "        loss = np.mean(batch_loss_list)\n",
    "        train_loss_list.append(loss)\n",
    "        print(' - loss: %f' % loss)\n",
    "\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        Y_hat = model(X_val.to(device)).detach().cpu()\n",
    "        val_loss = loss_fun(Y_val, Y_hat)\n",
    "        valid_loss_list.append(val_loss)\n",
    "        predicted = Y_hat\n",
    "        clear_output(wait=True)\n",
    "        k = 0\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        for m in range(6):\n",
    "          plt.subplot(3, 6, k+1)\n",
    "          plt.imshow(denormalize(X_val[m]))\n",
    "          # plt.imshow(X_val[m][0].numpy(), cmap='gray')\n",
    "          plt.title('Input')\n",
    "          plt.axis('off')\n",
    "\n",
    "          plt.subplot(3, 6, k+7)\n",
    "          plt.imshow(denormalize(predicted[m]))\n",
    "          # plt.imshow(predicted[m], cmap='gray')\n",
    "          plt.title('Output')\n",
    "          plt.axis('off')\n",
    "\n",
    "          plt.subplot(3, 6, k+13)\n",
    "          plt.imshow(denormalize(Y_val[m]))\n",
    "          # plt.imshow(Y_val[m][0], cmap='gray')\n",
    "          plt.title('Target')\n",
    "          plt.axis('off')\n",
    "          \n",
    "          k+=1\n",
    "        plt.suptitle('%d / %d - loss: %f , val loss: %f' % (epoch+1, epochs, loss, val_loss))\n",
    "        plt.show()\n",
    "\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        plt.plot(train_loss_list, 'b', label = \"Train loss\")\n",
    "        plt.plot(valid_loss_list, 'orange', label = \"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCn1j7nofDjw"
   },
   "source": [
    "First version - big latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "QVCnM68T5C28",
    "outputId": "dd72ea7b-2be5-4426-a4c7-b60980c47069"
   },
   "outputs": [],
   "source": [
    "model = ConvAutoEncoder().to(device)\n",
    "train(model, optim.Adam(model.parameters()), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjLzHvBQfKws"
   },
   "source": [
    "Version 2 - decreased latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "mKxgKWrj8jV4",
    "outputId": "77ae3bd0-fd4a-4731-a6fa-2c343d380be3"
   },
   "outputs": [],
   "source": [
    "model2 = ConvAutoEncoder2().to(device)\n",
    "train(model2, optim.Adam(model2.parameters()), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7ZxiCbLfPRw"
   },
   "source": [
    "Version 3 - experiments on down/upsampling an fully connected bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "RxX07nyTE0hE",
    "outputId": "0b70556d-f276-470b-89bc-76124b1d9fb2"
   },
   "outputs": [],
   "source": [
    "model3 = ConvAutoEncoder3().to(device)\n",
    "train(model3, optim.Adam(model3.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "Glq_UyQiI3vs",
    "outputId": "29dc3de9-78e8-4658-ee97-a7c46932100c"
   },
   "outputs": [],
   "source": [
    "# After removing fully connected layer\n",
    "model3 = ConvAutoEncoder3().to(device)\n",
    "train(model3, optim.Adam(model3.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9TUakkdgaNE"
   },
   "outputs": [],
   "source": [
    "# After removing alternative downsampling/upsampling\n",
    "model3 = ConvAutoEncoder3().to(device)\n",
    "train(model3, optim.Adam(model3.parameters()), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pscCHkGJgbbM"
   },
   "source": [
    "Version 4 - added skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "1k1Kz1PXArEA",
    "outputId": "608a79d6-5a1e-40f0-d237-77324ea066bd"
   },
   "outputs": [],
   "source": [
    "modelSkip = ConvAutoEncoderSkip().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "w5IVZNPzgg3o",
    "outputId": "2d021f9a-799d-411b-e796-30cbb4838246"
   },
   "outputs": [],
   "source": [
    "modelSkip2 = ConvAutoEncoderSkip2().to(device)\n",
    "train(modelSkip2, optim.Adam(modelSkip2.parameters()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "GjznqgW-vqTY",
    "outputId": "cdcc71f5-9cf3-4873-aa5d-82a317dfb188"
   },
   "outputs": [],
   "source": [
    "# After adding batchnorm\n",
    "modelSkip2 = ConvAutoEncoderSkip2().to(device)\n",
    "train(modelSkip2, optim.Adam(modelSkip2.parameters(), lr=0.001), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "93-Yo4tdDA-I",
    "outputId": "5f3da00b-6b93-4f76-f21d-d7da9a6502aa"
   },
   "outputs": [],
   "source": [
    "#Batchnorm dropout fully connected botleneck\n",
    "modelSkip2Dropout = ConvAutoEncoderSkip2Dropout().to(device)\n",
    "train(modelSkip2Dropout, optim.Adam(modelSkip2Dropout.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "-LN7oNmmE_Po",
    "outputId": "53d985cc-523d-442b-8185-a51788da14b7"
   },
   "outputs": [],
   "source": [
    "# No dropout conv bottleneck\n",
    "modelSkipOld = ConvAutoEncoderSkipOld().to(device)\n",
    "train(modelSkipOld, optim.Adam(modelSkipOld.parameters(), lr=0.001), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "k_P_web1IKd4",
    "outputId": "eca22e8f-ee90-44ed-9967-a0ec436de6d3"
   },
   "outputs": [],
   "source": [
    "# After adding dropout conv bottleneck\n",
    "modelSkip = ConvAutoEncoderSkip().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "ZSRDZUTxE6SM",
    "outputId": "12235297-a400-4603-a8ec-7ce9436a2815"
   },
   "outputs": [],
   "source": [
    "#conv bottleneck batchnorm\n",
    "modelSkipOld2 = ConvAutoEncoderSkipOld().to(device)\n",
    "train(modelSkipOld2, optim.Adam(modelSkipOld2.parameters(), lr=0.001), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgUiUmvxBh6A"
   },
   "source": [
    "Notes about the perfromance:\n",
    " * Tried decreasing learning rate but it seems that the default one (0.001) works the best at the moment\n",
    " * Batch normalization seems to stabilize the validation loss and decrease the loss very slightly\n",
    " * Increased the latent space size, since it seems that we aren't concerned about the \"encoding\" capabilities as long as the denoising works. It helped both for the \"fully connected\" bottleneck and the convolutional one. Now it seems that the network with convloutional bottleneck is slightly better, but it is not a big difference\n",
    " * Added dropout to all convolutional layers, increased the epoch amount to test it. As expected, the training loss is bigger, but I didn't see a decrease in the validation loss. After decreasing dropout to 0.1, the validation loss has decreased a bit\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AII210GgF5z0"
   },
   "source": [
    "### Batch size test\n",
    "\n",
    "used before is 128\n",
    "Testing a smaller one first - 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "UI8ADKiPGGuY",
    "outputId": "5427435c-5fc1-4b72-aeeb-ed25e0b50a57"
   },
   "outputs": [],
   "source": [
    "modelSkipOld2 = ConvAutoEncoderSkipOld().to(device)\n",
    "train(modelSkipOld2, optim.Adam(modelSkipOld2.parameters(), lr=0.001), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "8zRs2KEEOdd0",
    "outputId": "4bf7904c-30b4-4c90-f35b-22ca2600e82a"
   },
   "outputs": [],
   "source": [
    "modelSkipOld2 = ConvAutoEncoderSkipOld().to(device)\n",
    "train(modelSkipOld2, optim.Adam(modelSkipOld2.parameters(), lr=0.0001), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "sKLFn3CfO1Ps",
    "outputId": "c7d0104d-9ebc-4b42-b60e-44c58df0483e"
   },
   "outputs": [],
   "source": [
    "modelSkip = ConvAutoEncoderSkip().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3ymvef4GtpA"
   },
   "source": [
    "Testing 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "MZUOpwSWG3Fs",
    "outputId": "c9d9579f-a1b6-4e3a-af4c-3e0e354676c9"
   },
   "outputs": [],
   "source": [
    "modelSkipOld2 = ConvAutoEncoderSkipOld().to(device)\n",
    "train(modelSkipOld2, optim.Adam(modelSkipOld2.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXS-2z16I988"
   },
   "source": [
    "Same with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "L6Q2S2OYJAXo",
    "outputId": "e1ab76d1-7eb6-4c8b-f611-10dcee47b5d8"
   },
   "outputs": [],
   "source": [
    "modelSkip = ConvAutoEncoderSkip().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuQmN0XKHgRo"
   },
   "source": [
    "Testing 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "gF8wLxZ4Hffo",
    "outputId": "8c50dffe-0a8f-439d-ba41-5e5a2c254aff"
   },
   "outputs": [],
   "source": [
    "modelSkipOld2 = ConvAutoEncoderSkipOld().to(device)\n",
    "train(modelSkipOld2, optim.Adam(modelSkipOld2.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "fDGguNK-W32E",
    "outputId": "b9ca37bc-43ef-49f1-d07f-e7c41bec4c21"
   },
   "outputs": [],
   "source": [
    "modelSkip = ConvAutoEncoderSkip().to(device)\n",
    "train(modelSkip, optim.Adam(modelSkip.parameters(), lr=0.001), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwgcNuZqcxbs"
   },
   "source": [
    "It seems that the batch size of 64 is the best here. It also works best with dropout. 128 is fine, but produces slightly worse results, while 32 and 256 are visibly worse."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ConvolutionalAutoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
