{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPqWGqQeejhY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqojrNaSss2A"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import data\n",
    "  import dataset\n",
    "  import utils\n",
    "except:\n",
    "  print(\"Remember to load the python files to colab\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4jjXrVOsbY0",
    "outputId": "d66ad247-b2d6-4e79-e720-210e5a5d70c4"
   },
   "outputs": [],
   "source": [
    "!cd ..\n",
    "!mkdir data\n",
    "!cd data\n",
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz\n",
    "!rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Or006izmu-f4",
    "outputId": "3d9e5fe6-4c84-44a9-f42e-1109720a1bbf"
   },
   "outputs": [],
   "source": [
    "!pip install -U albumentations\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2jx5OpMgC4g",
    "outputId": "bd52375b-563f-43dc-fe39-ecd5dbf905e9"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeabDelStMzU"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.load_cifar_10_data(\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDTfph3_slw4"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# transform = {\n",
    "#         'train': transforms.Compose([\n",
    "#             transforms.Resize((32, 32)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, ), (0.5, ))\n",
    "#         ]),\n",
    "#         'test': transforms.Compose([\n",
    "#             transforms.Resize((32, 32)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, ), (0.5, ))\n",
    "#         ])\n",
    "#     }\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.GaussNoise(var_limit=(30, 70), mean=0, p=1),\n",
    "    # A.MultiplicativeNoise()\n",
    "    # A.Blur(p=1)\n",
    "    A.CoarseDropout(max_height=2, max_width=2, max_holes=3)\n",
    "])\n",
    "\n",
    "preprocess_transform = A.Compose([\n",
    "    # transforms.Resize((32, 32)),\n",
    "    A.Normalize(mean = [0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ToTensorV2()\n",
    "    \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "trainset = dataset.Cifar10AutoEncoderDataset(train_data, preprocess_transform, transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = dataset.Cifar10AutoEncoderDataset(test_data, preprocess_transform, transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wx2F7sMBCzA"
   },
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "  image = np.swapaxes(np.swapaxes(img.numpy(), 0, 2), 0, 1)\n",
    "  MEAN = 255 * np.array([0.5, 0.5, 0.5])\n",
    "  STD = 255 * np.array([0.5, 0.5, 0.5])\n",
    "  image = ((image * STD)+ MEAN).astype(int)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "XrlMzTwpxIGI",
    "outputId": "43f1abf9-5292-4359-e4be-315956a0707f"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure()\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(denormalize(images[i]))\n",
    "    # plt.imshow(images[i].numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(denormalize(labels[i]))\n",
    "    # plt.imshow(labels[i].numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6aqKM0ggWRI"
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        \n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool0 = nn.Conv2d(32, 32, 2, padding=0, stride=2)  # 32 -> 16\n",
    "        self.enc_conv1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.Conv2d(64, 64, 2, padding=0, stride=2)  # 16 -> 8\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.Conv2d(128, 128,2, padding=0, stride=2)  # 8 -> 4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(128,128,2,stride=2)  # 4 -> 8\n",
    "        self.dec_conv0 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)   # 8 -> 16\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(32,32,2,stride=2)   # 16 -> 32\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.dec_conv_fin = nn.Conv2d(32, 3, 1, padding=0)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encoder\n",
    "        e0 = F.leaky_relu(self.enc_conv0(x))\n",
    "        e1 = F.leaky_relu(self.enc_conv1(self.pool0(e0)))\n",
    "        e2 = F.leaky_relu(self.enc_conv2(self.pool1(e1)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.leaky_relu(self.bottleneck_conv(self.pool2(e2)))\n",
    "      \n",
    "        # decoder\n",
    "        d0 = F.leaky_relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.leaky_relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.leaky_relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        out = F.tanh(self.dec_conv_fin(d2))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ncDLpoG42rQ"
   },
   "outputs": [],
   "source": [
    "def train(model, opt, epochs):\n",
    "\n",
    "    def loss_fun(y_real, y_pred):\n",
    "      # loss = nn.CrossEntropyLoss(weight=torch.tensor([1,5]).float().to(device))\n",
    "      loss = torch.nn.MSELoss()\n",
    "      # output = loss(y_pred, y_real.squeeze(1).long())\n",
    "      output = loss(y_pred, y_real)\n",
    "      return output\n",
    "\n",
    "    X_val, Y_val = next(iter(test_loader))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for minibatch_no, (X_batch, Y_batch) in enumerate(train_loader, 0):\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            loss = loss_fun(Y_batch, Y_pred)  # forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            # calculate metrics to show the user\n",
    "            avg_loss += loss / len(X_batch)\n",
    "        toc = time()\n",
    "        print(' - loss: %f' % avg_loss)\n",
    "\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        Y_hat = model(X_val.to(device)).detach().cpu()\n",
    "        predicted = Y_hat\n",
    "        clear_output(wait=True)\n",
    "        k = 0\n",
    "        for m in range(6):\n",
    "          plt.subplot(3, 6, k+1)\n",
    "          plt.imshow(denormalize(X_val[m]))\n",
    "          # plt.imshow(X_val[m][0].numpy(), cmap='gray')\n",
    "          plt.title('Input')\n",
    "          plt.axis('off')\n",
    "\n",
    "          plt.subplot(3, 6, k+7)\n",
    "          plt.imshow(denormalize(predicted[m]))\n",
    "          # plt.imshow(predicted[m], cmap='gray')\n",
    "          plt.title('Output')\n",
    "          plt.axis('off')\n",
    "\n",
    "          plt.subplot(3, 6, k+13)\n",
    "          plt.imshow(denormalize(Y_val[m]))\n",
    "          # plt.imshow(Y_val[m][0], cmap='gray')\n",
    "          plt.title('Target')\n",
    "          plt.axis('off')\n",
    "          \n",
    "          k+=1\n",
    "        plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "QVCnM68T5C28",
    "outputId": "dd72ea7b-2be5-4426-a4c7-b60980c47069"
   },
   "outputs": [],
   "source": [
    "model = ConvAutoEncoder().to(device)\n",
    "train(model, optim.Adam(model.parameters()), 30)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ConvolutionalAutoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
